{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/kevinxu95/Data/order.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:500000]\n",
    "df = df[['sortorderid', 'productcode', 'sortquantity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.pivot_table(index='sortorderid', columns='productcode', values='sortquantity')\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total']= df.sum(axis=1)\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>productcode</th>\n",
       "      <th>Total</th>\n",
       "      <th>11013221</th>\n",
       "      <th>11013269</th>\n",
       "      <th>12013906</th>\n",
       "      <th>13010117</th>\n",
       "      <th>13010120</th>\n",
       "      <th>13010126</th>\n",
       "      <th>14014502</th>\n",
       "      <th>15010405</th>\n",
       "      <th>15010407</th>\n",
       "      <th>...</th>\n",
       "      <th>61023116</th>\n",
       "      <th>62010203</th>\n",
       "      <th>89023701</th>\n",
       "      <th>99020028</th>\n",
       "      <th>99020033</th>\n",
       "      <th>99020035</th>\n",
       "      <th>99020114</th>\n",
       "      <th>99020115</th>\n",
       "      <th>99022509</th>\n",
       "      <th>99026911</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sortorderid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00006908-6FA7-4157-9824-7153FCDCD5F0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00007299-B267-4BC1-8A88-1947986132D7</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000D98A-A389-48C5-A328-76ED869DC223</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00014E36-F1A4-414A-917C-39FC8E056135</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001B275-8600-48AD-B446-6B092C24F865</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "productcode                           Total  11013221  11013269  12013906  \\\n",
       "sortorderid                                                                 \n",
       "00006908-6FA7-4157-9824-7153FCDCD5F0    1.0       0.0       0.0       0.0   \n",
       "00007299-B267-4BC1-8A88-1947986132D7    6.0       0.0       0.0       0.0   \n",
       "0000D98A-A389-48C5-A328-76ED869DC223    8.0       0.0       0.0       0.0   \n",
       "00014E36-F1A4-414A-917C-39FC8E056135    1.0       0.0       0.0       0.0   \n",
       "0001B275-8600-48AD-B446-6B092C24F865    4.0       0.0       0.0       0.0   \n",
       "\n",
       "productcode                           13010117  13010120  13010126  14014502  \\\n",
       "sortorderid                                                                    \n",
       "00006908-6FA7-4157-9824-7153FCDCD5F0       0.0       0.0       0.0       0.0   \n",
       "00007299-B267-4BC1-8A88-1947986132D7       0.0       0.0       0.0       0.0   \n",
       "0000D98A-A389-48C5-A328-76ED869DC223       0.0       0.0       0.0       0.0   \n",
       "00014E36-F1A4-414A-917C-39FC8E056135       0.0       0.0       0.0       0.0   \n",
       "0001B275-8600-48AD-B446-6B092C24F865       0.0       0.0       0.0       0.0   \n",
       "\n",
       "productcode                           15010405  15010407  ...  61023116  \\\n",
       "sortorderid                                               ...             \n",
       "00006908-6FA7-4157-9824-7153FCDCD5F0       0.0       0.0  ...       0.0   \n",
       "00007299-B267-4BC1-8A88-1947986132D7       0.0       0.0  ...       0.0   \n",
       "0000D98A-A389-48C5-A328-76ED869DC223       0.0       0.0  ...       0.0   \n",
       "00014E36-F1A4-414A-917C-39FC8E056135       0.0       0.0  ...       0.0   \n",
       "0001B275-8600-48AD-B446-6B092C24F865       0.0       0.0  ...       0.0   \n",
       "\n",
       "productcode                           62010203  89023701  99020028  99020033  \\\n",
       "sortorderid                                                                    \n",
       "00006908-6FA7-4157-9824-7153FCDCD5F0       0.0       0.0       0.0       0.0   \n",
       "00007299-B267-4BC1-8A88-1947986132D7       0.0       0.0       0.0       0.0   \n",
       "0000D98A-A389-48C5-A328-76ED869DC223       0.0       0.0       0.0       0.0   \n",
       "00014E36-F1A4-414A-917C-39FC8E056135       0.0       0.0       0.0       0.0   \n",
       "0001B275-8600-48AD-B446-6B092C24F865       0.0       0.0       0.0       0.0   \n",
       "\n",
       "productcode                           99020035  99020114  99020115  99022509  \\\n",
       "sortorderid                                                                    \n",
       "00006908-6FA7-4157-9824-7153FCDCD5F0       0.0       0.0       0.0       0.0   \n",
       "00007299-B267-4BC1-8A88-1947986132D7       0.0       0.0       0.0       0.0   \n",
       "0000D98A-A389-48C5-A328-76ED869DC223       0.0       0.0       0.0       0.0   \n",
       "00014E36-F1A4-414A-917C-39FC8E056135       0.0       0.0       0.0       0.0   \n",
       "0001B275-8600-48AD-B446-6B092C24F865       0.0       0.0       0.0       0.0   \n",
       "\n",
       "productcode                           99026911  \n",
       "sortorderid                                     \n",
       "00006908-6FA7-4157-9824-7153FCDCD5F0       0.0  \n",
       "00007299-B267-4BC1-8A88-1947986132D7       0.0  \n",
       "0000D98A-A389-48C5-A328-76ED869DC223       0.0  \n",
       "00014E36-F1A4-414A-917C-39FC8E056135       0.0  \n",
       "0001B275-8600-48AD-B446-6B092C24F865       0.0  \n",
       "\n",
       "[5 rows x 169 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['Total']!=1]\n",
    "df2 = df[df['Total']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_int = []\n",
    "for idx, i in enumerate(df1['Total']):\n",
    "    if i != int(i):\n",
    "        not_int.append(idx)\n",
    "\n",
    "df1 = df1.drop(df1.index[not_int])\n",
    "df1 = df1.iloc[:,1:]\n",
    "df1 = df1.drop(df1.columns[df1.max(axis=0)==1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>productcode</th>\n",
       "      <th>11013221</th>\n",
       "      <th>13010117</th>\n",
       "      <th>13010120</th>\n",
       "      <th>13010126</th>\n",
       "      <th>14014502</th>\n",
       "      <th>15010405</th>\n",
       "      <th>15010407</th>\n",
       "      <th>21023018</th>\n",
       "      <th>22023425</th>\n",
       "      <th>31010803</th>\n",
       "      <th>...</th>\n",
       "      <th>53023024</th>\n",
       "      <th>53023030</th>\n",
       "      <th>53023032</th>\n",
       "      <th>53023034</th>\n",
       "      <th>53070124</th>\n",
       "      <th>61023116</th>\n",
       "      <th>89023701</th>\n",
       "      <th>99020028</th>\n",
       "      <th>99020033</th>\n",
       "      <th>99020035</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>184182.00000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "      <td>184182.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002834</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08048</td>\n",
       "      <td>0.033163</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.017570</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.061672</td>\n",
       "      <td>0.068655</td>\n",
       "      <td>0.042489</td>\n",
       "      <td>0.020575</td>\n",
       "      <td>0.018639</td>\n",
       "      <td>0.099371</td>\n",
       "      <td>0.027370</td>\n",
       "      <td>0.013785</td>\n",
       "      <td>0.067553</td>\n",
       "      <td>0.071180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39039</td>\n",
       "      <td>0.256794</td>\n",
       "      <td>0.027957</td>\n",
       "      <td>0.023874</td>\n",
       "      <td>0.166194</td>\n",
       "      <td>0.029286</td>\n",
       "      <td>0.033516</td>\n",
       "      <td>0.036619</td>\n",
       "      <td>0.032198</td>\n",
       "      <td>0.037569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "productcode       11013221       13010117       13010120       13010126  \\\n",
       "count        184182.000000  184182.000000  184182.000000  184182.000000   \n",
       "mean              0.002834       0.002166       0.001634       0.000391   \n",
       "std               0.061672       0.068655       0.042489       0.020575   \n",
       "min               0.000000       0.000000       0.000000       0.000000   \n",
       "25%               0.000000       0.000000       0.000000       0.000000   \n",
       "50%               0.000000       0.000000       0.000000       0.000000   \n",
       "75%               0.000000       0.000000       0.000000       0.000000   \n",
       "max              10.000000      20.000000       6.000000       3.000000   \n",
       "\n",
       "productcode       14014502       15010405       15010407       21023018  \\\n",
       "count        184182.000000  184182.000000  184182.000000  184182.000000   \n",
       "mean              0.000261       0.005353       0.000391       0.000103   \n",
       "std               0.018639       0.099371       0.027370       0.013785   \n",
       "min               0.000000       0.000000       0.000000       0.000000   \n",
       "25%               0.000000       0.000000       0.000000       0.000000   \n",
       "50%               0.000000       0.000000       0.000000       0.000000   \n",
       "75%               0.000000       0.000000       0.000000       0.000000   \n",
       "max               2.000000       3.000000       3.000000       2.000000   \n",
       "\n",
       "productcode       22023425       31010803  ...      53023024       53023030  \\\n",
       "count        184182.000000  184182.000000  ...  184182.00000  184182.000000   \n",
       "mean              0.002867       0.004566  ...       0.08048       0.033163   \n",
       "std               0.067553       0.071180  ...       0.39039       0.256794   \n",
       "min               0.000000       0.000000  ...       0.00000       0.000000   \n",
       "25%               0.000000       0.000000  ...       0.00000       0.000000   \n",
       "50%               0.000000       0.000000  ...       0.00000       0.000000   \n",
       "75%               0.000000       0.000000  ...       0.00000       0.000000   \n",
       "max               2.000000       2.000000  ...       5.00000       5.000000   \n",
       "\n",
       "productcode       53023032       53023034       53070124       61023116  \\\n",
       "count        184182.000000  184182.000000  184182.000000  184182.000000   \n",
       "mean              0.000500       0.000375       0.017570       0.000423   \n",
       "std               0.027957       0.023874       0.166194       0.029286   \n",
       "min               0.000000       0.000000       0.000000       0.000000   \n",
       "25%               0.000000       0.000000       0.000000       0.000000   \n",
       "50%               0.000000       0.000000       0.000000       0.000000   \n",
       "75%               0.000000       0.000000       0.000000       0.000000   \n",
       "max               2.000000       2.000000       3.000000       5.000000   \n",
       "\n",
       "productcode       89023701       99020028       99020033       99020035  \n",
       "count        184182.000000  184182.000000  184182.000000  184182.000000  \n",
       "mean              0.000766       0.000364       0.000548       0.000434  \n",
       "std               0.033516       0.036619       0.032198       0.037569  \n",
       "min               0.000000       0.000000       0.000000       0.000000  \n",
       "25%               0.000000       0.000000       0.000000       0.000000  \n",
       "50%               0.000000       0.000000       0.000000       0.000000  \n",
       "75%               0.000000       0.000000       0.000000       0.000000  \n",
       "max               2.000000      10.000000      10.000000      10.000000  \n",
       "\n",
       "[8 rows x 106 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 184182, 106])\n",
      "running k-means for equal size clusters on cuda:0..\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 746.00 MiB (GPU 0; 3.95 GiB total capacity; 2.20 GiB already allocated; 289.50 MiB free; 2.20 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dd8648863fec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mchoices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/balanced_kmeans/__init__.py\u001b[0m in \u001b[0;36mkmeans_equal\u001b[0;34m(X, num_clusters, cluster_size, max_iters, initial_state, update_centers, progress, tol)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# randomly group vectors to clusters (forgy initialization)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/balanced_kmeans/__init__.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(X, num_clusters)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 746.00 MiB (GPU 0; 3.95 GiB total capacity; 2.20 GiB already allocated; 289.50 MiB free; 2.20 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from balanced_kmeans import kmeans_equal\n",
    "import torch\n",
    "\n",
    "\n",
    "dim = df1.shape[1]\n",
    "batch_size = 10\n",
    "N = df1.shape[0] // batch_size + 1\n",
    "num_clusters = 8\n",
    "cluster_size = N // num_clusters\n",
    "device = 'cuda'\n",
    "\n",
    "# X = torch.tensor(df1.values, device=device)\n",
    "X = torch.rand(batch_size, N, dim, device=device)\n",
    "print(X.shape)\n",
    "choices, centers = kmeans_equal(X, num_clusters=num_clusters, cluster_size=cluster_size, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('/home/kevinxu95/Data/order_df1.csv',index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
